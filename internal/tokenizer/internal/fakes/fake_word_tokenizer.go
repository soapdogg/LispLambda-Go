// Code generated by counterfeiter. DO NOT EDIT.
package fakes

import (
	"lisp_lambda-go/internal/tokenizer/internal"
	"sync"
)

type FakeWordTokenizer struct {
	TokenizeWordStub        func(string) []string
	tokenizeWordMutex       sync.RWMutex
	tokenizeWordArgsForCall []struct {
		arg1 string
	}
	tokenizeWordReturns struct {
		result1 []string
	}
	tokenizeWordReturnsOnCall map[int]struct {
		result1 []string
	}
	invocations      map[string][][]interface{}
	invocationsMutex sync.RWMutex
}

func (fake *FakeWordTokenizer) TokenizeWord(arg1 string) []string {
	fake.tokenizeWordMutex.Lock()
	ret, specificReturn := fake.tokenizeWordReturnsOnCall[len(fake.tokenizeWordArgsForCall)]
	fake.tokenizeWordArgsForCall = append(fake.tokenizeWordArgsForCall, struct {
		arg1 string
	}{arg1})
	stub := fake.TokenizeWordStub
	fakeReturns := fake.tokenizeWordReturns
	fake.recordInvocation("TokenizeWord", []interface{}{arg1})
	fake.tokenizeWordMutex.Unlock()
	if stub != nil {
		return stub(arg1)
	}
	if specificReturn {
		return ret.result1
	}
	return fakeReturns.result1
}

func (fake *FakeWordTokenizer) TokenizeWordCallCount() int {
	fake.tokenizeWordMutex.RLock()
	defer fake.tokenizeWordMutex.RUnlock()
	return len(fake.tokenizeWordArgsForCall)
}

func (fake *FakeWordTokenizer) TokenizeWordCalls(stub func(string) []string) {
	fake.tokenizeWordMutex.Lock()
	defer fake.tokenizeWordMutex.Unlock()
	fake.TokenizeWordStub = stub
}

func (fake *FakeWordTokenizer) TokenizeWordArgsForCall(i int) string {
	fake.tokenizeWordMutex.RLock()
	defer fake.tokenizeWordMutex.RUnlock()
	argsForCall := fake.tokenizeWordArgsForCall[i]
	return argsForCall.arg1
}

func (fake *FakeWordTokenizer) TokenizeWordReturns(result1 []string) {
	fake.tokenizeWordMutex.Lock()
	defer fake.tokenizeWordMutex.Unlock()
	fake.TokenizeWordStub = nil
	fake.tokenizeWordReturns = struct {
		result1 []string
	}{result1}
}

func (fake *FakeWordTokenizer) TokenizeWordReturnsOnCall(i int, result1 []string) {
	fake.tokenizeWordMutex.Lock()
	defer fake.tokenizeWordMutex.Unlock()
	fake.TokenizeWordStub = nil
	if fake.tokenizeWordReturnsOnCall == nil {
		fake.tokenizeWordReturnsOnCall = make(map[int]struct {
			result1 []string
		})
	}
	fake.tokenizeWordReturnsOnCall[i] = struct {
		result1 []string
	}{result1}
}

func (fake *FakeWordTokenizer) Invocations() map[string][][]interface{} {
	fake.invocationsMutex.RLock()
	defer fake.invocationsMutex.RUnlock()
	fake.tokenizeWordMutex.RLock()
	defer fake.tokenizeWordMutex.RUnlock()
	copiedInvocations := map[string][][]interface{}{}
	for key, value := range fake.invocations {
		copiedInvocations[key] = value
	}
	return copiedInvocations
}

func (fake *FakeWordTokenizer) recordInvocation(key string, args []interface{}) {
	fake.invocationsMutex.Lock()
	defer fake.invocationsMutex.Unlock()
	if fake.invocations == nil {
		fake.invocations = map[string][][]interface{}{}
	}
	if fake.invocations[key] == nil {
		fake.invocations[key] = [][]interface{}{}
	}
	fake.invocations[key] = append(fake.invocations[key], args)
}

var _ internal.WordTokenizer = new(FakeWordTokenizer)
